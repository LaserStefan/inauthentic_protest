{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c67a9450-6959-474c-aab2-06eda087c006",
   "metadata": {},
   "source": [
    "# Topic Modelling/Voyant text preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6056c097-ba6b-470e-a332-2a363f219dc8",
   "metadata": {},
   "source": [
    "To make topic topelling possible, you need to strip the text of all insignificant strips of words and make them as coherent as possible without losing quality. Key to this is a cleaning master function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f9a7964-8d06-4892-b6c7-258aa900432d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from os.path import join\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from numpy import nan\n",
    "\n",
    "# alternative model building package\n",
    "# import sklearn\n",
    "# from sklearn.decomposition import NMF\n",
    "\n",
    "# package to clean text\n",
    "import re\n",
    "\n",
    "# Load modules for cleaning tasks\n",
    "import nltk\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import GermanStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8f87d42-0070-4e0e-a810-2fe970d6af43",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "src = \"/media/s/Linux_storage/Analyse_Verkehrswende_Transformation/Data/Greenwashing\"\n",
    "\n",
    "df = pd.read_csv(join(src, 'WordTree.csv'), encoding='utf-8', dtype='unicode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4e52268-61d4-4196-88bd-63288ddba941",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard cleaning tasks\n",
    "\n",
    "def remove_links(tweet):\n",
    "    '''Takes a string and removes web links from it'''\n",
    "    tweet = re.sub(r'http\\S+', '', tweet) # remove http links\n",
    "    tweet = re.sub(r'bit.ly/\\S+', '', tweet) # remove bitly links\n",
    "    tweet = tweet.strip('[link]') # remove [links]\n",
    "    return tweet\n",
    "\n",
    "def remove_users(tweet):\n",
    "    '''Takes a string and removes retweet and @user information'''\n",
    "    tweet = re.sub('RT @[\\w_]+:', '', tweet) # remove retweet ## Alternatives: RT @[\\w_]+: OR (RT\\s@[A-Za-z]+[A-Za-z0-9-_]+)\n",
    "    tweet = re.sub('@[A-Za-z0-9_]', '', tweet) # remove tweeted at ## Alternatives: @[A-Za-z0-9_]+ OR (@[A-Za-z]+[A-Za-z0-9-_]+)\n",
    "    return tweet\n",
    "\n",
    "my_stopwords = nltk.corpus.stopwords.words('english')\n",
    "word_rooter = nltk.stem.snowball.GermanStemmer(ignore_stopwords=False).stem\n",
    "#word_rooter2 = nltk.stem.snowball.PorterStemmer(ignore_stopwords=False).stem\n",
    "#my_punctuation = '!\"$%&\\'()*+,-./:;<=>?[\\\\]^_`{|}~•@' ## Alternatives: r'[^\\w\\s] OR !\"$%&\\'()*+,-./:;<=>?[\\\\]^_`{|}~•@ \n",
    "\n",
    "# cleaning master function\n",
    "def clean_tweet(tweet, bigrams=False): # change bigrams to True to enable further analysis\n",
    "    tweet = remove_users(tweet)\n",
    "    tweet = remove_links(tweet)\n",
    "    tweet = tweet.lower() # lower case\n",
    "    #tweet = re.sub('['+my_punctuation + ']+', ' ', tweet) # strip punctuation\n",
    "    tweet = re.sub(r'[^\\w\\s]', ' ', tweet) # strip punctuation\n",
    "    tweet = re.sub(r'\\b\\w{1,3}\\b', '', tweet, re.UNICODE)\n",
    "    tweet = re.sub('\\s+', ' ', tweet, re.UNICODE) # remove double spacing\n",
    "    tweet = re.sub('([0-9]+)', '', tweet, re.UNICODE) # remove numbers\n",
    "    tweet_token_list = [word for word in tweet.split(' ')\n",
    "                            if word not in my_stopwords] # remove stopwords\n",
    "    tweet_token_list = [word_rooter(word) if '#' not in word else word \n",
    "                        for word in tweet_token_list] # apply word rooter\n",
    "    #tweet_token_list = [word_rooter2(word) if '#' not in word else word \n",
    "    #                    for word in tweet_token_list] # apply word rooter\n",
    "    if bigrams:\n",
    "        tweet_token_list = tweet_token_list+[tweet_token_list[i]+'_'+tweet_token_list[i+1]\n",
    "                                            for i in range(len(tweet_token_list)-1)]\n",
    "    tweet = ' '.join(tweet_token_list)\n",
    "    return tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "712c53f4-c999-4a92-8160-1cb0514adafc",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\nSkip to main content\\nAdvertisementInternati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\nPlease enable cookies.\\nError\\n1020\\nRay ID:...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\nSkip to main content\\nAdvertisementInternati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>400 Bad request\\nYour browser sent an invalid ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\\nClose\\n \\n聽/聽\\n鈫惵犫啋\\n \\nSearch\\nSearch\\nYale...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2167</th>\n",
       "      <td>\\nWhat鈥檚 On\\nCulture\\nStyle\\nHealth &amp; Beauty\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2168</th>\n",
       "      <td>\\n \\nHome\\nSustainable Investment Week\\nESG\\nS...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2169</th>\n",
       "      <td>Not Acceptable!An appropriate representation o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2170</th>\n",
       "      <td>\\n \\nSign in\\nHome\\nNews\\nGlobal rubber market...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2171</th>\n",
       "      <td>Tuesday, July 13 2021      Breaking N...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2172 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Body\n",
       "0     \\nSkip to main content\\nAdvertisementInternati...\n",
       "1     \\nPlease enable cookies.\\nError\\n1020\\nRay ID:...\n",
       "2     \\nSkip to main content\\nAdvertisementInternati...\n",
       "3     400 Bad request\\nYour browser sent an invalid ...\n",
       "4     \\nClose\\n \\n聽/聽\\n鈫惵犫啋\\n \\nSearch\\nSearch\\nYale...\n",
       "...                                                 ...\n",
       "2167  \\nWhat鈥檚 On\\nCulture\\nStyle\\nHealth & Beauty\\n...\n",
       "2168  \\n \\nHome\\nSustainable Investment Week\\nESG\\nS...\n",
       "2169  Not Acceptable!An appropriate representation o...\n",
       "2170  \\n \\nSign in\\nHome\\nNews\\nGlobal rubber market...\n",
       "2171           Tuesday, July 13 2021      Breaking N...\n",
       "\n",
       "[2172 rows x 1 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "53531247-9d58-47d1-95da-1bb7ca1931f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['clean_text'] = df.Body.apply(clean_tweet) # This gets cleaned tweets\n",
    "\n",
    "#df['clean_tweet'] = df['clean_tweet'].apply(\n",
    "#    lambda x: x.replace(\"test\", \"\")) # Merge certain singular words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9f1ce6e8-4035-4d28-9d43-c04dd18f9d7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        skip main content advertisementinternational ...\n",
       "1        pleas enabl cooki error  eefd  access denied ...\n",
       "2        skip main content advertisementinternational ...\n",
       "3        requ your brows sent invalid requ _xd_ highly...\n",
       "4        clos 鈫惵犫啋 search search yal environment publi...\n",
       "                              ...                        \n",
       "2167     what鈥檚 cultur styl health beauty fashion jewe...\n",
       "2168     hom sustainabl investment week sustainabl inv...\n",
       "2169     acceptabl appropriat representation requested...\n",
       "2170     sign hom news global rubb market news economi...\n",
       "2171     tuesday july  breaking news giorgio chiellini...\n",
       "Name: clean_text, Length: 2172, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['clean_text']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7220315-98fe-4187-8e84-af933427b631",
   "metadata": {},
   "source": [
    "## Topic Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c5b7e6bd-e2a1-4e4f-8cd2-df7af9ece64a",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "src = \"/media/s/Linux_storage/Analyse_Verkehrswende_Transformation/Data/Greenwashing\"\n",
    "\n",
    "df = pd.read_csv(join(src, 'greenwashing_clean.csv'), encoding='utf-8', dtype='unicode', \n",
    "                   parse_dates=['created_at'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4c26065b-68e2-42f4-b1e0-7b96a200b8b1",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of        Unnamed: 0                   id                created_at  \\\n",
       "0          689365  1109566187342565384 2019-03-23 21:22:48+00:00   \n",
       "1          659519  1131217759877181440 2019-05-22 15:18:25+00:00   \n",
       "2          526567  1204674273023053824 2019-12-11 08:08:23+00:00   \n",
       "3          184374  1370839105123323905 2021-03-13 20:48:06+00:00   \n",
       "4          675614  1116158418350432256 2019-04-11 01:57:58+00:00   \n",
       "...           ...                  ...                       ...   \n",
       "186858     633541  1155997398130257920 2019-07-30 00:23:51+00:00   \n",
       "186859     633532  1156014938986434562 2019-07-30 01:33:33+00:00   \n",
       "186860     633526  1156030252881068032 2019-07-30 02:34:24+00:00   \n",
       "186861     633506  1156065050013999104 2019-07-30 04:52:41+00:00   \n",
       "186862     579462  1186349718823194630 2019-10-21 18:33:08+00:00   \n",
       "\n",
       "                                                     text  author.username  \\\n",
       "0       ADOS co-founder Yvette Carnell admits to being...      ImaniKushan   \n",
       "1       #VoluntariosModelo son esas personas que demue...        Corona_MX   \n",
       "2       Live from #COP25: Join us for a special event ...           UNFCCC   \n",
       "3       Hier mein versprochener #Ehrenrant zur beschis...  Doktor_FreakOut   \n",
       "4       These 10 spring outfits made from sustainable ...            hmusa   \n",
       "...                                                   ...              ...   \n",
       "186858  GreenBiz      When sustainability needs a two-...       earthblog2   \n",
       "186859  #OnTwitter \\nMe encuentro con esta noticia ABE...         artdiazl   \n",
       "186860  Die nerven echt mit ihrer #greenwashing-Lüge! ...           JVos63   \n",
       "186861  Greenwashing global logging | DW Documentary h...  Nola_Lee_Kelsey   \n",
       "186862  Et l’agence de com qui raconte tranquillement ...            ara7s   \n",
       "\n",
       "       author.public_metrics.followers_count  \\\n",
       "0                                       3935   \n",
       "1                                     527909   \n",
       "2                                     803978   \n",
       "3                                      28855   \n",
       "4                                     481471   \n",
       "...                                      ...   \n",
       "186858                                   226   \n",
       "186859                                   398   \n",
       "186860                                  1464   \n",
       "186861                                  3733   \n",
       "186862                                   195   \n",
       "\n",
       "       author.public_metrics.following_count  \\\n",
       "0                                       2893   \n",
       "1                                        986   \n",
       "2                                       1050   \n",
       "3                                        583   \n",
       "4                                       1446   \n",
       "...                                      ...   \n",
       "186858                                   553   \n",
       "186859                                  1137   \n",
       "186860                                   931   \n",
       "186861                                  4754   \n",
       "186862                                   666   \n",
       "\n",
       "       author.public_metrics.tweet_count  \\\n",
       "0                                  61744   \n",
       "1                                 117938   \n",
       "2                                  27680   \n",
       "3                                  57164   \n",
       "4                                  18665   \n",
       "...                                  ...   \n",
       "186858                              8855   \n",
       "186859                             38671   \n",
       "186860                             44136   \n",
       "186861                             22291   \n",
       "186862                             11863   \n",
       "\n",
       "                                        entities.hashtags  \\\n",
       "0       [{\"start\": 251, \"end\": 274, \"tag\": \"KnowingIsH...   \n",
       "1       [{\"start\": 0, \"end\": 18, \"tag\": \"VoluntariosMo...   \n",
       "2       [{\"start\": 10, \"end\": 16, \"tag\": \"COP25\"}, {\"s...   \n",
       "3       [{\"start\": 24, \"end\": 34, \"tag\": \"Ehrenrant\"},...   \n",
       "4       [{\"start\": 96, \"end\": 108, \"tag\": \"HMConscious\"}]   \n",
       "...                                                   ...   \n",
       "186858  [{\"start\": 153, \"end\": 166, \"tag\": \"Greenwashi...   \n",
       "186859      [{\"start\": 0, \"end\": 10, \"tag\": \"OnTwitter\"}]   \n",
       "186860  [{\"start\": 26, \"end\": 39, \"tag\": \"greenwashing...   \n",
       "186861  [{\"start\": 82, \"end\": 96, \"tag\": \"climatechang...   \n",
       "186862  [{\"start\": 154, \"end\": 167, \"tag\": \"greenwashi...   \n",
       "\n",
       "                                        entities.mentions  ...  \\\n",
       "0                                                     NaN  ...   \n",
       "1                                                     NaN  ...   \n",
       "2                                                     NaN  ...   \n",
       "3                                                     NaN  ...   \n",
       "4                                                     NaN  ...   \n",
       "...                                                   ...  ...   \n",
       "186858                                                NaN  ...   \n",
       "186859  [{\"start\": 67, \"end\": 76, \"username\": \"MMAChil...  ...   \n",
       "186860  [{\"start\": 89, \"end\": 104, \"username\": \"ExxonM...  ...   \n",
       "186861  [{\"start\": 73, \"end\": 81, \"username\": \"YouTube...  ...   \n",
       "186862                                                NaN  ...   \n",
       "\n",
       "       in_reply_to_user.username in_reply_to_user.url lang  \\\n",
       "0                            NaN                  NaN   en   \n",
       "1                            NaN                  NaN   es   \n",
       "2                            NaN                  NaN   en   \n",
       "3                            NaN                  NaN   de   \n",
       "4                            NaN                  NaN   en   \n",
       "...                          ...                  ...  ...   \n",
       "186858                       NaN                  NaN   en   \n",
       "186859                       NaN                  NaN   es   \n",
       "186860                       NaN                  NaN   de   \n",
       "186861                       NaN                  NaN   en   \n",
       "186862                       NaN                  NaN   fr   \n",
       "\n",
       "       public_metrics.like_count public_metrics.quote_count  \\\n",
       "0                           1565                        317   \n",
       "1                           3999                         21   \n",
       "2                           2846                        109   \n",
       "3                           3344                        221   \n",
       "4                           2647                         95   \n",
       "...                          ...                        ...   \n",
       "186858                         0                          0   \n",
       "186859                         0                          0   \n",
       "186860                         0                          0   \n",
       "186861                         0                          0   \n",
       "186862                         1                          0   \n",
       "\n",
       "       public_metrics.reply_count public_metrics.retweet_count  \\\n",
       "0                             213                          996   \n",
       "1                             108                          996   \n",
       "2                             122                          994   \n",
       "3                             163                          991   \n",
       "4                              79                           99   \n",
       "...                           ...                          ...   \n",
       "186858                          0                            0   \n",
       "186859                          0                            0   \n",
       "186860                          0                            0   \n",
       "186861                          0                            0   \n",
       "186862                          0                            0   \n",
       "\n",
       "                                              clean_tweet  \\\n",
       "0       ados found yvett carnell admit being board mem...   \n",
       "1        voluntariosmodelo esas personas demuestran po...   \n",
       "2       liv from cop join special event climateemergency    \n",
       "3       versproch ehrenrant beschiss lag nation lag ga...   \n",
       "4       thes spring outfit mad from sustainabl materia...   \n",
       "...                                                   ...   \n",
       "186858  greenbiz when sustainability need conversation...   \n",
       "186859   ontwitt encuentro esta noticia aberrant opina...   \n",
       "186860   nerv echt greenwashing lug saub kraftstoff er...   \n",
       "186861  greenwashing global logging documentary outub ...   \n",
       "186862   agenc racont tranquillement typo choisi pour ...   \n",
       "\n",
       "                                                     urls  \\\n",
       "0       https://twitter.com/ImaniKushan/status/1109566...   \n",
       "1       http://voluntariosmodelo.com.mx https://twitte...   \n",
       "2          https://twitter.com/i/broadcasts/1BdxYeARYoYxX   \n",
       "3       https://twitter.com/Doktor_FreakOut/status/137...   \n",
       "4       https://twitter.com/hmusa/carousels/1116158288...   \n",
       "...                                                   ...   \n",
       "186858                                  http://grn.bz/pRH   \n",
       "186859  https://twitter.com/alecuevas/status/115007955...   \n",
       "186860  https://twitter.com/JVos63/status/115603025288...   \n",
       "186861                       https://youtu.be/GMp0IFAV41Q   \n",
       "186862  https://twitter.com/Paris2024/status/118634764...   \n",
       "\n",
       "                                                 hashtags  \n",
       "0                                  KnowingIsHalfTheBattle  \n",
       "1                                       VoluntariosModelo  \n",
       "2                                  COP25 ClimateEmergency  \n",
       "3                                       Ehrenrant Laschet  \n",
       "4                                             HMConscious  \n",
       "...                                                   ...  \n",
       "186858                                       Greenwashing  \n",
       "186859                                          OnTwitter  \n",
       "186860  greenwashing Erdöl SchämtEuch SponsoredAds Gef...  \n",
       "186861     climatechange fraud politics eco environmental  \n",
       "186862                             greenwashing paris2024  \n",
       "\n",
       "[186863 rows x 21 columns]>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c014be0b-6ba6-4d17-8bb7-1fff9e7a254d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9828cf62-9ea8-4f75-8eae-828c92c0540d",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-30-ff8ff9903f7f>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['clean_tweet'] = df['clean_tweet'].apply(\n"
     ]
    }
   ],
   "source": [
    "# Add additional stopwords\n",
    "df['clean_tweet'] = df['clean_tweet'].apply(\n",
    "    lambda x: x.replace(\"greenwashing\", \"\")) # Merge certain singular words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "da5f9ede-f0d4-42f0-9979-f26dde0cd639",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# the vectorizer object will be used to transform text to vector form\n",
    "vectorizer = CountVectorizer(max_df=0.9, min_df=25, token_pattern='\\w+|\\$[\\d\\.]+|\\S+')\n",
    "\n",
    "# apply transformation to get Matrix\n",
    "tf = vectorizer.fit_transform(df['clean_text']).toarray()\n",
    "#tf = vectorizer.fit_transform(df.pop('text'))\n",
    "\n",
    "# adding \"features\" columns as SparseSeries\n",
    "#for i, col in enumerate(vectorizer.get_feature_names()):\n",
    "#    df[col] = pd.SparseSeries(tf[:, i].toarray().ravel(), fill_value=0)\n",
    "\n",
    "# tf_feature_names tells us what word each column in the matric represents\n",
    "tf_feature_names = vectorizer.get_feature_names()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1c786f70-3646-440d-b355-a9b5d4b0557d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf_feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6fdc96d3-b994-47b3-bceb-b242e63f0815",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "number_of_topics = 15\n",
    "\n",
    "# Here we have two different models: LDA vs NFM. NFM might work better with Tweet data.\n",
    "model = LatentDirichletAllocation(n_components=number_of_topics, random_state=0)\n",
    "#model = NMF(n_components=None, random_state=0, alpha=.1, l1_ratio=.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dae494d1-f38d-4854-a547-06c2dd57e31e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(tf)\n",
    "\n",
    "def display_topics(model, feature_names, no_top_words):\n",
    "    topic_dict = {}\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        topic_dict[\"Topic %d words\" % (topic_idx)]= ['{}'.format(feature_names[i])\n",
    "                        for i in topic.argsort()[:-no_top_words - 1:-1]]\n",
    "        topic_dict[\"Topic %d weights\" % (topic_idx)]= ['{:.1f}'.format(topic[i])\n",
    "                        for i in topic.argsort()[:-no_top_words - 1:-1]]\n",
    "        df = pd.DataFrame(topic_dict)\n",
    "        df.to_csv('/media/s/Linux_storage/Analyse_Verkehrswende_Transformation/Data/Greenwashing' + '/' + 'topicmodelling_wordcloud.csv')\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f62f0bb3-79c9-4eee-ac12-60be2111eb08",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic 0 words</th>\n",
       "      <th>Topic 0 weights</th>\n",
       "      <th>Topic 1 words</th>\n",
       "      <th>Topic 1 weights</th>\n",
       "      <th>Topic 2 words</th>\n",
       "      <th>Topic 2 weights</th>\n",
       "      <th>Topic 3 words</th>\n",
       "      <th>Topic 3 weights</th>\n",
       "      <th>Topic 4 words</th>\n",
       "      <th>Topic 4 weights</th>\n",
       "      <th>...</th>\n",
       "      <th>Topic 10 words</th>\n",
       "      <th>Topic 10 weights</th>\n",
       "      <th>Topic 11 words</th>\n",
       "      <th>Topic 11 weights</th>\n",
       "      <th>Topic 12 words</th>\n",
       "      <th>Topic 12 weights</th>\n",
       "      <th>Topic 13 words</th>\n",
       "      <th>Topic 13 weights</th>\n",
       "      <th>Topic 14 words</th>\n",
       "      <th>Topic 14 weights</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>de</td>\n",
       "      <td>1765.4</td>\n",
       "      <td>2021</td>\n",
       "      <td>651.0</td>\n",
       "      <td>_x000d_</td>\n",
       "      <td>3576.0</td>\n",
       "      <td>聽</td>\n",
       "      <td>3553.6</td>\n",
       "      <td>climat</td>\n",
       "      <td>1149.2</td>\n",
       "      <td>...</td>\n",
       "      <td>esg</td>\n",
       "      <td>2577.2</td>\n",
       "      <td>green</td>\n",
       "      <td>1190.4</td>\n",
       "      <td>news</td>\n",
       "      <td>815.5</td>\n",
       "      <td>ago</td>\n",
       "      <td>770.3</td>\n",
       "      <td>climat</td>\n",
       "      <td>3424.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>product</td>\n",
       "      <td>1090.5</td>\n",
       "      <td>jul</td>\n",
       "      <td>375.2</td>\n",
       "      <td>_xd_</td>\n",
       "      <td>1010.5</td>\n",
       "      <td>2020</td>\n",
       "      <td>710.4</td>\n",
       "      <td>news</td>\n",
       "      <td>741.7</td>\n",
       "      <td>...</td>\n",
       "      <td>investment</td>\n",
       "      <td>2361.0</td>\n",
       "      <td>journal</td>\n",
       "      <td>369.6</td>\n",
       "      <td>environmental</td>\n",
       "      <td>786.0</td>\n",
       "      <td>bitcoin</td>\n",
       "      <td>362.0</td>\n",
       "      <td>鈥</td>\n",
       "      <td>2869.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>la</td>\n",
       "      <td>887.3</td>\n",
       "      <td>1</td>\n",
       "      <td>354.9</td>\n",
       "      <td>english</td>\n",
       "      <td>473.3</td>\n",
       "      <td>2019</td>\n",
       "      <td>676.7</td>\n",
       "      <td>鈥</td>\n",
       "      <td>725.2</td>\n",
       "      <td>...</td>\n",
       "      <td>fund</td>\n",
       "      <td>1973.5</td>\n",
       "      <td>data</td>\n",
       "      <td>271.8</td>\n",
       "      <td>business</td>\n",
       "      <td>768.8</td>\n",
       "      <td>hour</td>\n",
       "      <td>278.6</td>\n",
       "      <td>energy</td>\n",
       "      <td>2183.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>greenwashing</td>\n",
       "      <td>803.7</td>\n",
       "      <td>news</td>\n",
       "      <td>354.2</td>\n",
       "      <td>law</td>\n",
       "      <td>469.7</td>\n",
       "      <td>2018</td>\n",
       "      <td>631.5</td>\n",
       "      <td>eu</td>\n",
       "      <td>635.7</td>\n",
       "      <td>...</td>\n",
       "      <td>investor</td>\n",
       "      <td>1798.9</td>\n",
       "      <td>articl</td>\n",
       "      <td>254.1</td>\n",
       "      <td>event</td>\n",
       "      <td>725.7</td>\n",
       "      <td>min</td>\n",
       "      <td>265.3</td>\n",
       "      <td>fuel</td>\n",
       "      <td>1637.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>di</td>\n",
       "      <td>708.9</td>\n",
       "      <td>investing</td>\n",
       "      <td>341.9</td>\n",
       "      <td>program</td>\n",
       "      <td>435.3</td>\n",
       "      <td>email</td>\n",
       "      <td>599.9</td>\n",
       "      <td>green</td>\n",
       "      <td>601.8</td>\n",
       "      <td>...</td>\n",
       "      <td>financial</td>\n",
       "      <td>1419.1</td>\n",
       "      <td>greenwashing</td>\n",
       "      <td>219.7</td>\n",
       "      <td>contact</td>\n",
       "      <td>684.1</td>\n",
       "      <td>mining</td>\n",
       "      <td>243.5</td>\n",
       "      <td>oil</td>\n",
       "      <td>1534.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>en</td>\n",
       "      <td>706.8</td>\n",
       "      <td>icon</td>\n",
       "      <td>326.7</td>\n",
       "      <td>paid</td>\n",
       "      <td>421.3</td>\n",
       "      <td>march</td>\n",
       "      <td>587.9</td>\n",
       "      <td>energy</td>\n",
       "      <td>522.7</td>\n",
       "      <td>...</td>\n",
       "      <td>market</td>\n",
       "      <td>976.6</td>\n",
       "      <td>sustainability</td>\n",
       "      <td>211.7</td>\n",
       "      <td>new</td>\n",
       "      <td>662.4</td>\n",
       "      <td>energy</td>\n",
       "      <td>198.0</td>\n",
       "      <td>gas</td>\n",
       "      <td>1477.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>e</td>\n",
       "      <td>593.7</td>\n",
       "      <td>read</td>\n",
       "      <td>324.5</td>\n",
       "      <td>best</td>\n",
       "      <td>304.7</td>\n",
       "      <td>july</td>\n",
       "      <td>586.8</td>\n",
       "      <td>uk</td>\n",
       "      <td>510.4</td>\n",
       "      <td>...</td>\n",
       "      <td>investing</td>\n",
       "      <td>961.5</td>\n",
       "      <td>climat</td>\n",
       "      <td>205.2</td>\n",
       "      <td>us</td>\n",
       "      <td>658.2</td>\n",
       "      <td>pow</td>\n",
       "      <td>189.6</td>\n",
       "      <td>fossil</td>\n",
       "      <td>1424.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>claim</td>\n",
       "      <td>467.8</td>\n",
       "      <td>more</td>\n",
       "      <td>317.3</td>\n",
       "      <td>news</td>\n",
       "      <td>300.2</td>\n",
       "      <td>april</td>\n",
       "      <td>564.8</td>\n",
       "      <td>said</td>\n",
       "      <td>487.6</td>\n",
       "      <td>...</td>\n",
       "      <td>asset</td>\n",
       "      <td>948.9</td>\n",
       "      <td>bond</td>\n",
       "      <td>193.7</td>\n",
       "      <td>greenwashing</td>\n",
       "      <td>616.5</td>\n",
       "      <td>鈥</td>\n",
       "      <td>187.9</td>\n",
       "      <td>chang</td>\n",
       "      <td>1351.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>consum</td>\n",
       "      <td>365.7</td>\n",
       "      <td>string</td>\n",
       "      <td>279.5</td>\n",
       "      <td>consum</td>\n",
       "      <td>223.1</td>\n",
       "      <td>february</td>\n",
       "      <td>549.5</td>\n",
       "      <td>july</td>\n",
       "      <td>475.8</td>\n",
       "      <td>...</td>\n",
       "      <td>鈥</td>\n",
       "      <td>870.3</td>\n",
       "      <td>issu</td>\n",
       "      <td>193.0</td>\n",
       "      <td>search</td>\n",
       "      <td>585.0</td>\n",
       "      <td>project</td>\n",
       "      <td>167.6</td>\n",
       "      <td>emission</td>\n",
       "      <td>1230.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>le</td>\n",
       "      <td>351.3</td>\n",
       "      <td>july</td>\n",
       "      <td>236.3</td>\n",
       "      <td>free</td>\n",
       "      <td>190.6</td>\n",
       "      <td>2017</td>\n",
       "      <td>526.3</td>\n",
       "      <td>european</td>\n",
       "      <td>461.0</td>\n",
       "      <td>...</td>\n",
       "      <td>risk</td>\n",
       "      <td>850.9</td>\n",
       "      <td>environmental</td>\n",
       "      <td>187.0</td>\n",
       "      <td>email</td>\n",
       "      <td>562.0</td>\n",
       "      <td>vaccin</td>\n",
       "      <td>159.6</td>\n",
       "      <td>new</td>\n",
       "      <td>1187.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Topic 0 words Topic 0 weights Topic 1 words Topic 1 weights Topic 2 words  \\\n",
       "0            de          1765.4          2021           651.0       _x000d_   \n",
       "1       product          1090.5           jul           375.2          _xd_   \n",
       "2            la           887.3             1           354.9       english   \n",
       "3  greenwashing           803.7          news           354.2           law   \n",
       "4            di           708.9     investing           341.9       program   \n",
       "5            en           706.8          icon           326.7          paid   \n",
       "6             e           593.7          read           324.5          best   \n",
       "7         claim           467.8          more           317.3          news   \n",
       "8        consum           365.7        string           279.5        consum   \n",
       "9            le           351.3          july           236.3          free   \n",
       "\n",
       "  Topic 2 weights Topic 3 words Topic 3 weights Topic 4 words Topic 4 weights  \\\n",
       "0          3576.0             聽          3553.6        climat          1149.2   \n",
       "1          1010.5          2020           710.4          news           741.7   \n",
       "2           473.3          2019           676.7             鈥           725.2   \n",
       "3           469.7          2018           631.5            eu           635.7   \n",
       "4           435.3         email           599.9         green           601.8   \n",
       "5           421.3         march           587.9        energy           522.7   \n",
       "6           304.7          july           586.8            uk           510.4   \n",
       "7           300.2         april           564.8          said           487.6   \n",
       "8           223.1      february           549.5          july           475.8   \n",
       "9           190.6          2017           526.3      european           461.0   \n",
       "\n",
       "   ... Topic 10 words Topic 10 weights  Topic 11 words Topic 11 weights  \\\n",
       "0  ...            esg           2577.2           green           1190.4   \n",
       "1  ...     investment           2361.0         journal            369.6   \n",
       "2  ...           fund           1973.5            data            271.8   \n",
       "3  ...       investor           1798.9          articl            254.1   \n",
       "4  ...      financial           1419.1    greenwashing            219.7   \n",
       "5  ...         market            976.6  sustainability            211.7   \n",
       "6  ...      investing            961.5          climat            205.2   \n",
       "7  ...          asset            948.9            bond            193.7   \n",
       "8  ...              鈥            870.3            issu            193.0   \n",
       "9  ...           risk            850.9   environmental            187.0   \n",
       "\n",
       "  Topic 12 words Topic 12 weights Topic 13 words Topic 13 weights  \\\n",
       "0           news            815.5            ago            770.3   \n",
       "1  environmental            786.0        bitcoin            362.0   \n",
       "2       business            768.8           hour            278.6   \n",
       "3          event            725.7            min            265.3   \n",
       "4        contact            684.1         mining            243.5   \n",
       "5            new            662.4         energy            198.0   \n",
       "6             us            658.2            pow            189.6   \n",
       "7   greenwashing            616.5              鈥            187.9   \n",
       "8         search            585.0        project            167.6   \n",
       "9          email            562.0         vaccin            159.6   \n",
       "\n",
       "  Topic 14 words Topic 14 weights  \n",
       "0         climat           3424.4  \n",
       "1              鈥           2869.6  \n",
       "2         energy           2183.4  \n",
       "3           fuel           1637.7  \n",
       "4            oil           1534.4  \n",
       "5            gas           1477.9  \n",
       "6         fossil           1424.2  \n",
       "7          chang           1351.7  \n",
       "8       emission           1230.4  \n",
       "9            new           1187.5  \n",
       "\n",
       "[10 rows x 30 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_top_words = 10\n",
    "display_topics(model, tf_feature_names, no_top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9df9a7cc-e9a9-48ca-b88b-f0b3578b62c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
